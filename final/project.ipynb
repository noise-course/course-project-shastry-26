{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29934a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Samples: 25798it [00:15, 1687.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import dpkt\n",
    "import pcapml_fe\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset to load\n",
    "PCAPML_PATH = \"traffic.pcapng\"\n",
    "\n",
    "# Directory to save individual pcaps\n",
    "PCAP_DIR = \"pcaps\"\n",
    "\n",
    "# Directory to save labels\n",
    "LABELS_CSV = \"labels.csv\"\n",
    "\n",
    "os.makedirs(PCAP_DIR, exist_ok=True)\n",
    "\n",
    "# convert sample metadata into a string\n",
    "def extract_label(sample):\n",
    "    meta = sample.metadata\n",
    "    parts = []\n",
    "    for p in meta.split(\",\"):\n",
    "        cleaned = p.strip()\n",
    "        if cleaned:\n",
    "            parts.append(cleaned)\n",
    "\n",
    "    lf = parts[0]\n",
    "\n",
    "    if \"-\" in lf:\n",
    "        lf = lf.split(\"-\", 1)[0]\n",
    "\n",
    "    return lf.strip()\n",
    "\n",
    "with open(LABELS_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Item\", \"Label\"])\n",
    "\n",
    "    for sample in tqdm(pcapml_fe.sampler(PCAPML_PATH), desc=\"Samples\"):\n",
    "        sid = str(sample.sid)\n",
    "        label = extract_label(sample)\n",
    "        pcap_name = f\"{sid}.pcap\"\n",
    "        pcap_path = os.path.join(PCAP_DIR, pcap_name)\n",
    "\n",
    "        pkts = sample.packets\n",
    "\n",
    "        # Find earliest timestamp in this sample to normalize\n",
    "        ts0 = float(\"inf\")\n",
    "        for p in pkts:\n",
    "            ts0 = min(ts0, p.ts)\n",
    "\n",
    "        with open(pcap_path, \"wb\") as pcap_f:\n",
    "            # write pcap file per sample\n",
    "            w = dpkt.pcap.Writer(pcap_f)\n",
    "            for pkt in pkts:\n",
    "                # dpkt requires positive timestamp so we normalize with ts0\n",
    "                norm_ts = max(0,pkt.ts - ts0)\n",
    "                w.writepkt(pkt.raw_bytes, ts=norm_ts)\n",
    "\n",
    "        writer.writerow([pcap_name, label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a9a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_ip,ipv4_ver_0,ipv4_ver_1,ipv4_ver_2,ipv4_ver_3,ipv4_hl_0,ipv4_hl_1,ipv4_hl_2,ipv4_hl_3,ipv4_tos_0,ipv4_tos_1,ipv4_tos_2,ipv4_tos_3,ipv4_tos_4,ipv4_tos_5,ipv4_tos_6,ipv4_tos_7,ipv4_tl_0,ipv4_tl_1,ipv4_tl_2,ipv4_tl_3,ipv4_tl_4,ipv4_tl_5,ipv4_tl_6,ipv4_tl_7,ipv4_tl_8,ipv4_tl_9,ipv4_tl_10,ipv4_tl_11,ipv4_tl_12,ipv4_tl_13,ipv4_tl_14,ipv4_tl_15,ipv4_id_0,ipv4_id_1,ipv4_id_2,ipv4_id_3,ipv4_id_4,ipv4_id_5,ipv4_id_6,ipv4_id_7,ipv4_id_8,ipv4_id_9,ipv4_id_10,ipv4_id_11,ipv4_id_12,ipv4_id_13,ipv4_id_14,ipv4_id_15,ipv4_rbit_0,ipv4_dfbit_0,ipv4_mfbit_0,ipv4_foff_0,ipv4_foff_1,ipv4_foff_2,ipv4_foff_3,ipv4_foff_4,ipv4_foff_5,ipv4_foff_6,ipv4_foff_7,ipv4_foff_8,ipv4_foff_9,ipv4_foff_10,ipv4_foff_11,ipv4_foff_12,ipv4_ttl_0,ipv4_ttl_1,ipv4_ttl_2,ipv4_ttl_3,ipv4_ttl_4,ipv4_ttl_5,ipv4_ttl_6,ipv4_ttl_7,ipv4_proto_0,ipv4_proto_1,ipv4_proto_2,ipv4_proto_3,ipv4_proto_4,ipv4_proto_5,ipv4_proto_6,ipv4_proto_7,ipv4_cksum_0,ipv4_cksum_1,ipv4_cksum_2,ipv4_cksum_3,ipv4_cksum_4,ipv4_cksum_5,ipv4_cksum_6,ipv4_cksum_7,ipv4_cksum_8,ipv4_cksum_9,ipv4_cksum_10,ipv4_cksum_11,ipv4_cksum_12,ipv4_cksum_13,ipv4_cksum_14,ipv4_cksum_15,ipv4_src_0,ipv4_src_1,ipv4_src_2,ipv4_src_3,ipv4_src_4,ipv4_src_5,ipv4_src_6,ipv4_src_7,ipv4_src_8,ipv4_src_9,ipv4_src_10,ipv4_src_11,ipv4_src_12,ipv4_src_13,ipv4_src_14,ipv4_src_15,ipv4_src_16,ipv4_src_17,ipv4_src_18,ipv4_src_19,ipv4_src_20,ipv4_src_21,ipv4_src_22,ipv4_src_23,ipv4_src_24,ipv4_src_25,ipv4_src_26,ipv4_src_27,ipv4_src_28,ipv4_src_29,ipv4_src_30,ipv4_src_31,ipv4_dst_0,ipv4_dst_1,ipv4_dst_2,ipv4_dst_3,ipv4_dst_4,ipv4_dst_5,ipv4_dst_6,ipv4_dst_7,ipv4_dst_8,ipv4_dst_9,ipv4_dst_10,ipv4_dst_11,ipv4_dst_12,ipv4_dst_13,ipv4_dst_14,ipv4_dst_15,ipv4_dst_16,ipv4_dst_17,ipv4_dst_18,ipv4_dst_19,ipv4_dst_20,ipv4_dst_21,ipv4_dst_22,ipv4_dst_23,ipv4_dst_24,ipv4_dst_25,ipv4_dst_26,ipv4_dst_27,ipv4_dst_28,ipv4_dst_29,ipv4_dst_30,ipv4_dst_31,ipv4_opt_0,ipv4_opt_1,ipv4_opt_2,ipv4_opt_3,ipv4_opt_4,ipv4_opt_5,ipv4_opt_6,ipv4_opt_7,ipv4_opt_8,ipv4_opt_9,ipv4_opt_10,ipv4_opt_11,ipv4_opt_12,ipv4_opt_13,ipv4_opt_14,ipv4_opt_15,ipv4_opt_16,ipv4_opt_17,ipv4_opt_18,ipv4_opt_19,ipv4_opt_20,ipv4_opt_21,ipv4_opt_22,ipv4_opt_23,ipv4_opt_24,ipv4_opt_25,ipv4_opt_26,ipv4_opt_27,ipv4_opt_28,ipv4_opt_29,ipv4_opt_30,ipv4_opt_31,ipv4_opt_32,ipv4_opt_33,ipv4_opt_34,ipv4_opt_35,ipv4_opt_36,ipv4_opt_37,ipv4_opt_38,ipv4_opt_39,ipv4_opt_40,ipv4_opt_41,ipv4_opt_42,ipv4_opt_43,ipv4_opt_44,ipv4_opt_45,ipv4_opt_46,ipv4_opt_47,ipv4_opt_48,ipv4_opt_49,ipv4_opt_50,ipv4_opt_51,ipv4_opt_52,ipv4_opt_53,ipv4_opt_54,ipv4_opt_55,ipv4_opt_56,ipv4_opt_57,ipv4_opt_58,ipv4_opt_59,ipv4_opt_60,ipv4_opt_61,ipv4_opt_62,ipv4_opt_63,ipv4_opt_64,ipv4_opt_65,ipv4_opt_66,ipv4_opt_67,ipv4_opt_68,ipv4_opt_69,ipv4_opt_70,ipv4_opt_71,ipv4_opt_72,ipv4_opt_73,ipv4_opt_74,ipv4_opt_75,ipv4_opt_76,ipv4_opt_77,ipv4_opt_78,ipv4_opt_79,ipv4_opt_80,ipv4_opt_81,ipv4_opt_82,ipv4_opt_83,ipv4_opt_84,ipv4_opt_85,ipv4_opt_86,ipv4_opt_87,ipv4_opt_88,ipv4_opt_89,ipv4_opt_90,ipv4_opt_91,ipv4_opt_92,ipv4_opt_93,ipv4_opt_94,ipv4_opt_95,ipv4_opt_96,ipv4_opt_97,ipv4_opt_98,ipv4_opt_99,ipv4_opt_100,ipv4_opt_101,ipv4_opt_102,ipv4_opt_103,ipv4_opt_104,ipv4_opt_105,ipv4_opt_106,ipv4_opt_107,ipv4_opt_108,ipv4_opt_109,ipv4_opt_110,ipv4_opt_111,ipv4_opt_112,ipv4_opt_113,ipv4_opt_114,ipv4_opt_115,ipv4_opt_116,ipv4_opt_117,ipv4_opt_118,ipv4_opt_119,ipv4_opt_120,ipv4_opt_121,ipv4_opt_122,ipv4_opt_123,ipv4_opt_124,ipv4_opt_125,ipv4_opt_126,ipv4_opt_127,ipv4_opt_128,ipv4_opt_129,ipv4_opt_130,ipv4_opt_131,ipv4_opt_132,ipv4_opt_133,ipv4_opt_134,ipv4_opt_135,ipv4_opt_136,ipv4_opt_137,ipv4_opt_138,ipv4_opt_139,ipv4_opt_140,ipv4_opt_141,ipv4_opt_142,ipv4_opt_143,ipv4_opt_144,ipv4_opt_145,ipv4_opt_146,ipv4_opt_147,ipv4_opt_148,ipv4_opt_149,ipv4_opt_150,ipv4_opt_151,ipv4_opt_152,ipv4_opt_153,ipv4_opt_154,ipv4_opt_155,ipv4_opt_156,ipv4_opt_157,ipv4_opt_158,ipv4_opt_159,ipv4_opt_160,ipv4_opt_161,ipv4_opt_162,ipv4_opt_163,ipv4_opt_164,ipv4_opt_165,ipv4_opt_166,ipv4_opt_167,ipv4_opt_168,ipv4_opt_169,ipv4_opt_170,ipv4_opt_171,ipv4_opt_172,ipv4_opt_173,ipv4_opt_174,ipv4_opt_175,ipv4_opt_176,ipv4_opt_177,ipv4_opt_178,ipv4_opt_179,ipv4_opt_180,ipv4_opt_181,ipv4_opt_182,ipv4_opt_183,ipv4_opt_184,ipv4_opt_185,ipv4_opt_186,ipv4_opt_187,ipv4_opt_188,ipv4_opt_189,ipv4_opt_190,ipv4_opt_191,ipv4_opt_192,ipv4_opt_193,ipv4_opt_194,ipv4_opt_195,ipv4_opt_196,ipv4_opt_197,ipv4_opt_198,ipv4_opt_199,ipv4_opt_200,ipv4_opt_201,ipv4_opt_202,ipv4_opt_203,ipv4_opt_204,ipv4_opt_205,ipv4_opt_206,ipv4_opt_207,ipv4_opt_208,ipv4_opt_209,ipv4_opt_210,ipv4_opt_211,ipv4_opt_212,ipv4_opt_213,ipv4_opt_214,ipv4_opt_215,ipv4_opt_216,ipv4_opt_217,ipv4_opt_218,ipv4_opt_219,ipv4_opt_220,ipv4_opt_221,ipv4_opt_222,ipv4_opt_223,ipv4_opt_224,ipv4_opt_225,ipv4_opt_226,ipv4_opt_227,ipv4_opt_228,ipv4_opt_229,ipv4_opt_230,ipv4_opt_231,ipv4_opt_232,ipv4_opt_233,ipv4_opt_234,ipv4_opt_235,ipv4_opt_236,ipv4_opt_237,ipv4_opt_238,ipv4_opt_239,ipv4_opt_240,ipv4_opt_241,ipv4_opt_242,ipv4_opt_243,ipv4_opt_244,ipv4_opt_245,ipv4_opt_246,ipv4_opt_247,ipv4_opt_248,ipv4_opt_249,ipv4_opt_250,ipv4_opt_251,ipv4_opt_252,ipv4_opt_253,ipv4_opt_254,ipv4_opt_255,ipv4_opt_256,ipv4_opt_257,ipv4_opt_258,ipv4_opt_259,ipv4_opt_260,ipv4_opt_261,ipv4_opt_262,ipv4_opt_263,ipv4_opt_264,ipv4_opt_265,ipv4_opt_266,ipv4_opt_267,ipv4_opt_268,ipv4_opt_269,ipv4_opt_270,ipv4_opt_271,ipv4_opt_272,ipv4_opt_273,ipv4_opt_274,ipv4_opt_275,ipv4_opt_276,ipv4_opt_277,ipv4_opt_278,ipv4_opt_279,ipv4_opt_280,ipv4_opt_281,ipv4_opt_282,ipv4_opt_283,ipv4_opt_284,ipv4_opt_285,ipv4_opt_286,ipv4_opt_287,ipv4_opt_288,ipv4_opt_289,ipv4_opt_290,ipv4_opt_291,ipv4_opt_292,ipv4_opt_293,ipv4_opt_294,ipv4_opt_295,ipv4_opt_296,ipv4_opt_297,ipv4_opt_298,ipv4_opt_299,ipv4_opt_300,ipv4_opt_301,ipv4_opt_302,ipv4_opt_303,ipv4_opt_304,ipv4_opt_305,ipv4_opt_306,ipv4_opt_307,ipv4_opt_308,ipv4_opt_309,ipv4_opt_310,ipv4_opt_311,ipv4_opt_312,ipv4_opt_313,ipv4_opt_314,ipv4_opt_315,ipv4_opt_316,ipv4_opt_317,ipv4_opt_318,ipv4_opt_319,tcp_sprt_0,tcp_sprt_1,tcp_sprt_2,tcp_sprt_3,tcp_sprt_4,tcp_sprt_5,tcp_sprt_6,tcp_sprt_7,tcp_sprt_8,tcp_sprt_9,tcp_sprt_10,tcp_sprt_11,tcp_sprt_12,tcp_sprt_13,tcp_sprt_14,tcp_sprt_15,tcp_dprt_0,tcp_dprt_1,tcp_dprt_2,tcp_dprt_3,tcp_dprt_4,tcp_dprt_5,tcp_dprt_6,tcp_dprt_7,tcp_dprt_8,tcp_dprt_9,tcp_dprt_10,tcp_dprt_11,tcp_dprt_12,tcp_dprt_13,tcp_dprt_14,tcp_dprt_15,tcp_seq_0,tcp_seq_1,tcp_seq_2,tcp_seq_3,tcp_seq_4,tcp_seq_5,tcp_seq_6,tcp_seq_7,tcp_seq_8,tcp_seq_9,tcp_seq_10,tcp_seq_11,tcp_seq_12,tcp_seq_13,tcp_seq_14,tcp_seq_15,tcp_seq_16,tcp_seq_17,tcp_seq_18,tcp_seq_19,tcp_seq_20,tcp_seq_21,tcp_seq_22,tcp_seq_23,tcp_seq_24,tcp_seq_25,tcp_seq_26,tcp_seq_27,tcp_seq_28,tcp_seq_29,tcp_seq_30,tcp_seq_31,tcp_ackn_0,tcp_ackn_1,tcp_ackn_2,tcp_ackn_3,tcp_ackn_4,tcp_ackn_5,tcp_ackn_6,tcp_ackn_7,tcp_ackn_8,tcp_ackn_9,tcp_ackn_10,tcp_ackn_11,tcp_ackn_12,tcp_ackn_13,tcp_ackn_14,tcp_ackn_15,tcp_ackn_16,tcp_ackn_17,tcp_ackn_18,tcp_ackn_19,tcp_ackn_20,tcp_ackn_21,tcp_ackn_22,tcp_ackn_23,tcp_ackn_24,tcp_ackn_25,tcp_ackn_26,tcp_ackn_27,tcp_ackn_28,tcp_ackn_29,tcp_ackn_30,tcp_ackn_31,tcp_doff_0,tcp_doff_1,tcp_doff_2,tcp_doff_3,tcp_res_0,tcp_res_1,tcp_res_2,tcp_ns_0,tcp_cwr_0,tcp_ece_0,tcp_urg_0,tcp_ackf_0,tcp_psh_0,tcp_rst_0,tcp_syn_0,tcp_fin_0,tcp_wsize_0,tcp_wsize_1,tcp_wsize_2,tcp_wsize_3,tcp_wsize_4,tcp_wsize_5,tcp_wsize_6,tcp_wsize_7,tcp_wsize_8,tcp_wsize_9,tcp_wsize_10,tcp_wsize_11,tcp_wsize_12,tcp_wsize_13,tcp_wsize_14,tcp_wsize_15,tcp_cksum_0,tcp_cksum_1,tcp_cksum_2,tcp_cksum_3,tcp_cksum_4,tcp_cksum_5,tcp_cksum_6,tcp_cksum_7,tcp_cksum_8,tcp_cksum_9,tcp_cksum_10,tcp_cksum_11,tcp_cksum_12,tcp_cksum_13,tcp_cksum_14,tcp_cksum_15,tcp_urp_0,tcp_urp_1,tcp_urp_2,tcp_urp_3,tcp_urp_4,tcp_urp_5,tcp_urp_6,tcp_urp_7,tcp_urp_8,tcp_urp_9,tcp_urp_10,tcp_urp_11,tcp_urp_12,tcp_urp_13,tcp_urp_14,tcp_urp_15,tcp_opt_0,tcp_opt_1,tcp_opt_2,tcp_opt_3,tcp_opt_4,tcp_opt_5,tcp_opt_6,tcp_opt_7,tcp_opt_8,tcp_opt_9,tcp_opt_10,tcp_opt_11,tcp_opt_12,tcp_opt_13,tcp_opt_14,tcp_opt_15,tcp_opt_16,tcp_opt_17,tcp_opt_18,tcp_opt_19,tcp_opt_20,tcp_opt_21,tcp_opt_22,tcp_opt_23,tcp_opt_24,tcp_opt_25,tcp_opt_26,tcp_opt_27,tcp_opt_28,tcp_opt_29,tcp_opt_30,tcp_opt_31,tcp_opt_32,tcp_opt_33,tcp_opt_34,tcp_opt_35,tcp_opt_36,tcp_opt_37,tcp_opt_38,tcp_opt_39,tcp_opt_40,tcp_opt_41,tcp_opt_42,tcp_opt_43,tcp_opt_44,tcp_opt_45,tcp_opt_46,tcp_opt_47,tcp_opt_48,tcp_opt_49,tcp_opt_50,tcp_opt_51,tcp_opt_52,tcp_opt_53,tcp_opt_54,tcp_opt_55,tcp_opt_56,tcp_opt_57,tcp_opt_58,tcp_opt_59,tcp_opt_60,tcp_opt_61,tcp_opt_62,tcp_opt_63,tcp_opt_64,tcp_opt_65,tcp_opt_66,tcp_opt_67,tcp_opt_68,tcp_opt_69,tcp_opt_70,tcp_opt_71,tcp_opt_72,tcp_opt_73,tcp_opt_74,tcp_opt_75,tcp_opt_76,tcp_opt_77,tcp_opt_78,tcp_opt_79,tcp_opt_80,tcp_opt_81,tcp_opt_82,tcp_opt_83,tcp_opt_84,tcp_opt_85,tcp_opt_86,tcp_opt_87,tcp_opt_88,tcp_opt_89,tcp_opt_90,tcp_opt_91,tcp_opt_92,tcp_opt_93,tcp_opt_94,tcp_opt_95,tcp_opt_96,tcp_opt_97,tcp_opt_98,tcp_opt_99,tcp_opt_100,tcp_opt_101,tcp_opt_102,tcp_opt_103,tcp_opt_104,tcp_opt_105,tcp_opt_106,tcp_opt_107,tcp_opt_108,tcp_opt_109,tcp_opt_110,tcp_opt_111,tcp_opt_112,tcp_opt_113,tcp_opt_114,tcp_opt_115,tcp_opt_116,tcp_opt_117,tcp_opt_118,tcp_opt_119,tcp_opt_120,tcp_opt_121,tcp_opt_122,tcp_opt_123,tcp_opt_124,tcp_opt_125,tcp_opt_126,tcp_opt_127,tcp_opt_128,tcp_opt_129,tcp_opt_130,tcp_opt_131,tcp_opt_132,tcp_opt_133,tcp_opt_134,tcp_opt_135,tcp_opt_136,tcp_opt_137,tcp_opt_138,tcp_opt_139,tcp_opt_140,tcp_opt_141,tcp_opt_142,tcp_opt_143,tcp_opt_144,tcp_opt_145,tcp_opt_146,tcp_opt_147,tcp_opt_148,tcp_opt_149,tcp_opt_150,tcp_opt_151,tcp_opt_152,tcp_opt_153,tcp_opt_154,tcp_opt_155,tcp_opt_156,tcp_opt_157,tcp_opt_158,tcp_opt_159,tcp_opt_160,tcp_opt_161,tcp_opt_162,tcp_opt_163,tcp_opt_164,tcp_opt_165,tcp_opt_166,tcp_opt_167,tcp_opt_168,tcp_opt_169,tcp_opt_170,tcp_opt_171,tcp_opt_172,tcp_opt_173,tcp_opt_174,tcp_opt_175,tcp_opt_176,tcp_opt_177,tcp_opt_178,tcp_opt_179,tcp_opt_180,tcp_opt_181,tcp_opt_182,tcp_opt_183,tcp_opt_184,tcp_opt_185,tcp_opt_186,tcp_opt_187,tcp_opt_188,tcp_opt_189,tcp_opt_190,tcp_opt_191,tcp_opt_192,tcp_opt_193,tcp_opt_194,tcp_opt_195,tcp_opt_196,tcp_opt_197,tcp_opt_198,tcp_opt_199,tcp_opt_200,tcp_opt_201,tcp_opt_202,tcp_opt_203,tcp_opt_204,tcp_opt_205,tcp_opt_206,tcp_opt_207,tcp_opt_208,tcp_opt_209,tcp_opt_210,tcp_opt_211,tcp_opt_212,tcp_opt_213,tcp_opt_214,tcp_opt_215,tcp_opt_216,tcp_opt_217,tcp_opt_218,tcp_opt_219,tcp_opt_220,tcp_opt_221,tcp_opt_222,tcp_opt_223,tcp_opt_224,tcp_opt_225,tcp_opt_226,tcp_opt_227,tcp_opt_228,tcp_opt_229,tcp_opt_230,tcp_opt_231,tcp_opt_232,tcp_opt_233,tcp_opt_234,tcp_opt_235,tcp_opt_236,tcp_opt_237,tcp_opt_238,tcp_opt_239,tcp_opt_240,tcp_opt_241,tcp_opt_242,tcp_opt_243,tcp_opt_244,tcp_opt_245,tcp_opt_246,tcp_opt_247,tcp_opt_248,tcp_opt_249,tcp_opt_250,tcp_opt_251,tcp_opt_252,tcp_opt_253,tcp_opt_254,tcp_opt_255,tcp_opt_256,tcp_opt_257,tcp_opt_258,tcp_opt_259,tcp_opt_260,tcp_opt_261,tcp_opt_262,tcp_opt_263,tcp_opt_264,tcp_opt_265,tcp_opt_266,tcp_opt_267,tcp_opt_268,tcp_opt_269,tcp_opt_270,tcp_opt_271,tcp_opt_272,tcp_opt_273,tcp_opt_274,tcp_opt_275,tcp_opt_276,tcp_opt_277,tcp_opt_278,tcp_opt_279,tcp_opt_280,tcp_opt_281,tcp_opt_282,tcp_opt_283,tcp_opt_284,tcp_opt_285,tcp_opt_286,tcp_opt_287,tcp_opt_288,tcp_opt_289,tcp_opt_290,tcp_opt_291,tcp_opt_292,tcp_opt_293,tcp_opt_294,tcp_opt_295,tcp_opt_296,tcp_opt_297,tcp_opt_298,tcp_opt_299,tcp_opt_300,tcp_opt_301,tcp_opt_302,tcp_opt_303,tcp_opt_304,tcp_opt_305,tcp_opt_306,tcp_opt_307,tcp_opt_308,tcp_opt_309,tcp_opt_310,tcp_opt_311,tcp_opt_312,tcp_opt_313,tcp_opt_314,tcp_opt_315,tcp_opt_316,tcp_opt_317,tcp_opt_318,tcp_opt_319\n",
      "103.119.149.71,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,0,1,0,0,0,1,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,1,0,0,1,0,1,1,0,1,1,0,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,1,1,0,0,1,0,0,0,1,0,1,1,0,0,0,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1\n"
     ]
    }
   ],
   "source": [
    "# I set 7 arbitrarily but the idea is to create a standard train matrix size\n",
    "# Example command\n",
    "# nprint -4 -t -c 7 -P pcaps/273992.pcap | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11789bb",
   "metadata": {},
   "source": [
    "I am not sure if different nprint versions have different command structures, however, here is the help menu from the version I am running (1.2.1):\n",
    "```\n",
    "-4, --ipv4                 include ipv4 headers\n",
    "-6, --ipv6                 include ipv6 headers\n",
    "-A, --absolute_timestamps  include absolute timestmap field\n",
    "-c, --count=INTEGER        number of packets to parse (if not all)\n",
    "-C, --csv_file=FILE        csv (hex packets) infile\n",
    "-d, --device=STRING        device to capture from if live capture\n",
    "-e, --eth                  include eth headers\n",
    "-f, --filter=STRING        filter for libpcap\n",
    "-F, --fill_int=INT8_T      integer to fill missing bits with\n",
    "-h, --nprint_filter_help   print regex possibilities\n",
    "-i, --icmp                 include icmp headers\n",
    "-N, --nPrint_file=FILE     nPrint infile\n",
    "-O, --write_index=INTEGER  Output file Index (first column) Options:\n",
    "                            \n",
    "                            0: source IP (default)\n",
    "                            \n",
    "                            1: destination IP\n",
    "                            \n",
    "                            2: source port\n",
    "                            \n",
    "                            3: destination port\n",
    "                            \n",
    "                            4: flow (5-tuple)\n",
    "                            \n",
    "                            5: wlan tx mac\n",
    "-p, --payload=PAYLOAD_SIZE include n bytes of payload\n",
    "-P, --pcap_file=FILE       pcap infile\n",
    "-r, --radiotap             include radiotap headers\n",
    "-R, --relative_timestamps  include relative timestamp field\n",
    "-S, --stats                print stats about packets processed when finished\n",
    "-t, --tcp                  include tcp headers\n",
    "-u, --udp                  include udp headers\n",
    "-V, --verbose              print human readable packets with nPrints\n",
    "-w, --wlan                 include wlan headers\n",
    "-W, --write_file=FILE      file for output, else stdout\n",
    "-x, --nprint_filter=STRING regex to filter bits out of nPrint. nprint -h for\n",
    "                            details\n",
    "-?, --help                 Give this help list\n",
    "    --usage                Give a short usage message\n",
    "    --version              Print program version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803baaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25798/25798 [10:11<00:00, 42.21it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (25798, 6720)\n",
      "y shape: (25798,)\n",
      "labels: {'avtech': 0, 'huawei': 1, 'roku': 2, 'axis': 3, 'h3c': 4, 'lancom': 5, 'mikrotik': 6, 'dell': 7, 'juniper': 8, 'cisco': 9, 'zte': 10, 'nec': 11, 'adtran': 12, 'ubiquoss': 13, 'chromecast': 14}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import io\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "PCAP_DIR = \"pcaps\"\n",
    "LABELS_CSV = \"labels.csv\"\n",
    "OUT_X = \"X_nprint.npy\"\n",
    "OUT_Y = \"y_nprint.npy\"\n",
    "OUT_LABEL_MAP = \"label_map_nprint.txt\"\n",
    "\n",
    "N_PACKETS = 7\n",
    "\n",
    "def nprint_vector(pcap_path, n_packets=N_PACKETS):\n",
    "    # same command as above\n",
    "    cmd = [\"nprint\", \"-4\", \"-t\", \"-c\", str(n_packets), \"-P\", pcap_path]\n",
    "    try:\n",
    "        result = subprocess.run(cmd,check=True,capture_output=True,text=True)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    text = result.stdout.strip()\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    #nprint outputs csv\n",
    "    reader = csv.reader(io.StringIO(text))\n",
    "    rows = list(reader)\n",
    "    if len(rows) <= 1:\n",
    "        return None\n",
    "\n",
    "    header = rows[0]\n",
    "    # discarding the index col\n",
    "    n_features = len(header) - 1\n",
    "    data_rows = rows[1:]\n",
    "\n",
    "    packet_feats = []\n",
    "    # Want to create uniform sized trainint/testing sets so truncate at n_packets\n",
    "    for row in data_rows[:n_packets]:\n",
    "        # drop index\n",
    "        feat_vals = row[1:]\n",
    "\n",
    "        # Add padding if necessary (gpt made this if statement)\n",
    "        if len(feat_vals) < n_features:\n",
    "            feat_vals += [\"-1\"]*(n_features-len(feat_vals))\n",
    "        feats = []\n",
    "\n",
    "        for v in feat_vals:\n",
    "            feats.append(int(v))\n",
    "        packet_feats.append(feats)\n",
    "\n",
    "    # suppose we have less than n_packets in this sample, we just pad by adding -1s\n",
    "    while len(packet_feats) < n_packets:\n",
    "        packet_feats.append([-1]* n_features)\n",
    "\n",
    "    # Return the features as a flattened array\n",
    "    return np.array(packet_feats, dtype=np.int8).flatten()\n",
    "\n",
    "def _worker(job):\n",
    "    pcap_path, label_str = job\n",
    "    vec = nprint_vector(pcap_path)\n",
    "    return vec, label_str\n",
    "\n",
    "def build_nprint_dataset_parallel():\n",
    "    with open(LABELS_CSV) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "\n",
    "    jobs = []\n",
    "    for r in rows:\n",
    "        pcap_path = os.path.join(PCAP_DIR, r[\"Item\"])\n",
    "        label_str = r[\"Label\"]\n",
    "        jobs.append((pcap_path, label_str))\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    labels_seen = {}\n",
    "\n",
    "    # Used GPT to modify this function to be multithreaded since it was taking so long to run\n",
    "    with ThreadPoolExecutor(max_workers=8) as ex:\n",
    "        for vec, label_str in tqdm(ex.map(_worker, jobs), total=len(jobs)):\n",
    "            if vec is None:\n",
    "                continue\n",
    "            \n",
    "            # idea is to create a new label mapping every time we see a new label\n",
    "            if label_str not in labels_seen:\n",
    "                labels_seen[label_str] = len(labels_seen)\n",
    "\n",
    "            X_list.append(vec)\n",
    "            y_list.append(labels_seen[label_str])\n",
    "\n",
    "    # X is now a matrix with each row representing a new sample and the row containing the flattened 7 nprint representations\n",
    "    X = np.stack(X_list)\n",
    "    # These are the corresponding labels (as integer class ids)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "    return X, y, labels_seen\n",
    "\n",
    "# build and save data\n",
    "# I decided to save the dataset since this process takes so long\n",
    "X, y, label_map = build_nprint_dataset_parallel()\n",
    "np.save(OUT_X, X)\n",
    "np.save(OUT_Y, y)\n",
    "\n",
    "# write the label map too\n",
    "with open(OUT_LABEL_MAP, \"w\") as f:\n",
    "    for label, idx in label_map.items():\n",
    "        f.write(f\"{idx},{label}\\n\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"labels:\", label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52280d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load saved data for next step\n",
    "X = np.load(\"X_nprint.npy\")\n",
    "y = np.load(\"y_nprint.npy\")\n",
    "\n",
    "# create the train test split (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2230702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8940645321678519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       430\n",
      "           1       0.80      0.75      0.78       282\n",
      "           2       0.85      0.94      0.89       481\n",
      "           3       0.85      0.95      0.90       531\n",
      "           4       0.88      0.81      0.84       276\n",
      "           5       0.94      0.92      0.93       285\n",
      "           6       0.81      0.67      0.73       272\n",
      "           7       0.85      0.87      0.86       290\n",
      "           8       0.96      0.92      0.94       289\n",
      "           9       0.97      0.94      0.95       290\n",
      "          10       0.96      0.94      0.95       285\n",
      "          11       0.98      0.99      0.98       290\n",
      "          12       0.98      0.98      0.98       290\n",
      "          13       0.98      0.93      0.95       295\n",
      "          14       0.99      0.98      0.99       574\n",
      "\n",
      "    accuracy                           0.90      5160\n",
      "   macro avg       0.91      0.89      0.90      5160\n",
      "weighted avg       0.90      0.90      0.90      5160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First trying with a random forest classifer\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0787df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.78500820\n",
      "Validation score: 0.610950\n",
      "Iteration 2, loss = 1.13859623\n",
      "Validation score: 0.730136\n",
      "Iteration 3, loss = 0.90572200\n",
      "Validation score: 0.773740\n",
      "Iteration 4, loss = 0.74436790\n",
      "Validation score: 0.804748\n",
      "Iteration 5, loss = 0.65368186\n",
      "Validation score: 0.805233\n",
      "Iteration 6, loss = 0.59900762\n",
      "Validation score: 0.823159\n",
      "Iteration 7, loss = 0.54989130\n",
      "Validation score: 0.843992\n",
      "Iteration 8, loss = 0.51773694\n",
      "Validation score: 0.829942\n",
      "Iteration 9, loss = 0.48238573\n",
      "Validation score: 0.833333\n",
      "Iteration 10, loss = 0.46053538\n",
      "Validation score: 0.866764\n",
      "Iteration 11, loss = 0.44340787\n",
      "Validation score: 0.815891\n",
      "Iteration 12, loss = 0.42075833\n",
      "Validation score: 0.814438\n",
      "Iteration 13, loss = 0.39405591\n",
      "Validation score: 0.860950\n",
      "Iteration 14, loss = 0.38429296\n",
      "Validation score: 0.875969\n",
      "Iteration 15, loss = 0.35442227\n",
      "Validation score: 0.868217\n",
      "Iteration 16, loss = 0.37086689\n",
      "Validation score: 0.811047\n",
      "Iteration 17, loss = 0.37177727\n",
      "Validation score: 0.846899\n",
      "Iteration 18, loss = 0.33650440\n",
      "Validation score: 0.873547\n",
      "Iteration 19, loss = 0.32500761\n",
      "Validation score: 0.886628\n",
      "Iteration 20, loss = 0.32566946\n",
      "Validation score: 0.862888\n",
      "Iteration 21, loss = 0.29952819\n",
      "Validation score: 0.871124\n",
      "Iteration 22, loss = 0.29084857\n",
      "Validation score: 0.858527\n",
      "Iteration 23, loss = 0.30389713\n",
      "Validation score: 0.842054\n",
      "Iteration 24, loss = 0.28249602\n",
      "Validation score: 0.865310\n",
      "Iteration 25, loss = 0.27837533\n",
      "Validation score: 0.869671\n",
      "Iteration 26, loss = 0.28342533\n",
      "Validation score: 0.871124\n",
      "Iteration 27, loss = 0.26649018\n",
      "Validation score: 0.863372\n",
      "Iteration 28, loss = 0.29403163\n",
      "Validation score: 0.878391\n",
      "Iteration 29, loss = 0.26079009\n",
      "Validation score: 0.866279\n",
      "Iteration 30, loss = 0.23581904\n",
      "Validation score: 0.880814\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Balanced Accuracy: 0.8703195954507035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       430\n",
      "           1       0.84      0.63      0.72       282\n",
      "           2       0.83      0.94      0.88       481\n",
      "           3       0.84      0.91      0.88       531\n",
      "           4       0.80      0.80      0.80       276\n",
      "           5       0.90      0.93      0.92       285\n",
      "           6       0.72      0.68      0.70       272\n",
      "           7       0.80      0.88      0.84       290\n",
      "           8       0.91      0.90      0.90       289\n",
      "           9       0.97      0.92      0.94       290\n",
      "          10       0.89      0.94      0.91       285\n",
      "          11       0.98      0.99      0.98       290\n",
      "          12       1.00      0.95      0.97       290\n",
      "          13       1.00      0.81      0.89       295\n",
      "          14       0.99      0.98      0.99       574\n",
      "\n",
      "    accuracy                           0.88      5160\n",
      "   macro avg       0.88      0.87      0.87      5160\n",
      "weighted avg       0.88      0.88      0.88      5160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    # Since we have a pretty sparse matrix, scale by std not mean\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"mlp\", MLPClassifier(\n",
    "        hidden_layer_sizes=(256,128),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=30,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        verbose=True,\n",
    "        batch_size=256,\n",
    "    )),\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
